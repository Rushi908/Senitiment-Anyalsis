{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8e206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16e0d317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                     1.0000            NaN  ...              NaN   \n",
       "1                     1.0000            NaN  ...              NaN   \n",
       "2                     0.6629            NaN  ...              NaN   \n",
       "3                     0.7039            NaN  ...              NaN   \n",
       "4                     1.0000            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "1            26             NaN                 NaN   \n",
       "2            27             NaN                 NaN   \n",
       "3           138             NaN                 NaN   \n",
       "4           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Sentiment.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b77f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text','sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06487e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  RT @ScottWalker: Didn't catch the full #GOPdeb...       True\n",
       "1  RT @RobGeorge: That Carly Fiorina is trending ...       True\n",
       "2  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...       True\n",
       "3  RT @GregAbbott_TX: @TedCruz: \"On my first day ...       True\n",
       "4  RT @warriorwoman91: I liked her and was happy ...      False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data['sentiment']= pd.get_dummies(data['sentiment'], drop_first = True)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db1a4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rushi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18bc0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ae454d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt scottwalker catch full gopdebate last night scott best line second walker http co zsff', 'rt robgeorge carly fiorina trend hour debate men complete gopdebate say', 'rt danscavino gopdebate w realdonaldtrump deliver highest rat history presidential debate trump http co']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(0, data.shape[0]):\n",
    "    tweet = re.sub('[^a-zA-Z]', ' ', data['text'][i])\n",
    "    tweet = tweet.lower()\n",
    "    tweet = word_tokenize(tweet)\n",
    "    \n",
    "    # Reduce words to their root form\n",
    "    tweet = [WordNetLemmatizer().lemmatize(w) for w in tweet if not w in set(stopwords.words('english'))]\n",
    "    \n",
    "    # Lemmatize verbs by specifying pos\n",
    "    tweet = [WordNetLemmatizer().lemmatize(w, pos='v') for w in tweet if not w in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    corpus.append(tweet)\n",
    "\n",
    "print(corpus[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9078d360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zsff</th>\n",
       "      <td>0.453518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catch</th>\n",
       "      <td>0.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>0.330405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.313011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.299403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scottwalker</th>\n",
       "      <td>0.282078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scott</th>\n",
       "      <td>0.274517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.249607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walker</th>\n",
       "      <td>0.235920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.182394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.179712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>0.125390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>0.120963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>0.073324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gopdebate</th>\n",
       "      <td>0.067839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prees</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predator</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicate</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepare</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TF-IDF\n",
       "zsff         0.453518\n",
       "catch        0.344600\n",
       "full         0.330405\n",
       "second       0.313011\n",
       "line         0.299403\n",
       "scottwalker  0.282078\n",
       "scott        0.274517\n",
       "best         0.249607\n",
       "walker       0.235920\n",
       "last         0.182394\n",
       "night        0.179712\n",
       "co           0.125390\n",
       "http         0.120963\n",
       "rt           0.073324\n",
       "gopdebate    0.067839\n",
       "prees        0.000000\n",
       "predator     0.000000\n",
       "predicate    0.000000\n",
       "prepare      0.000000\n",
       "predict      0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(corpus)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa05b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(corpus)):\n",
    "    corpus[i] = re.sub('co','', corpus[i])\n",
    "    corpus[i] = re.sub('rt','', corpus[i])\n",
    "    corpus[i] = re.sub('http','', corpus[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e0e1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "encoded_docs = tokenizer.texts_to_sequences(corpus)\n",
    "padded_sequence = pad_sequences(encoded_docs,maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aff4f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7ebc168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2db7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sttwalker catch full gopdebate last night stt best line send walker   zsff\n",
      "[252, 779, 564, 1, 15, 13, 204, 114, 354, 224, 72, 5278]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])\n",
    "print(encoded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caf4147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0  252\n",
      "  779  564    1   15   13  204  114  354  224   72 5278]\n"
     ]
    }
   ],
   "source": [
    "print(padded_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2810d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 200)           2598000   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 25, 200)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3)                 2448      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2600452 (9.92 MB)\n",
      "Trainable params: 2600452 (9.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_vector_length = 200\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length,\n",
    "                    input_length=25) )\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(3, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6466ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True False  True]\n"
     ]
    }
   ],
   "source": [
    "# converting the targets to numpy array to feed it into the model\n",
    "target = np.asarray(data['sentiment'])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82cdc22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "34/34 [==============================] - 5s 135ms/step - loss: 0.0618 - accuracy: 0.9857 - val_loss: 0.4531 - val_accuracy: 0.8509\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 0.0600 - accuracy: 0.9847 - val_loss: 0.4566 - val_accuracy: 0.8439\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0596 - accuracy: 0.9847 - val_loss: 0.4456 - val_accuracy: 0.8500\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 5s 133ms/step - loss: 0.0586 - accuracy: 0.9851 - val_loss: 0.4576 - val_accuracy: 0.8467\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0572 - accuracy: 0.9861 - val_loss: 0.4484 - val_accuracy: 0.8472\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0572 - accuracy: 0.9863 - val_loss: 0.4540 - val_accuracy: 0.8514\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0577 - accuracy: 0.9850 - val_loss: 0.4473 - val_accuracy: 0.8527\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0560 - accuracy: 0.9843 - val_loss: 0.4613 - val_accuracy: 0.8490\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 0.4605 - val_accuracy: 0.8481\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 0.0547 - accuracy: 0.9852 - val_loss: 0.4750 - val_accuracy: 0.8467\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 6s 165ms/step - loss: 0.0520 - accuracy: 0.9857 - val_loss: 0.4602 - val_accuracy: 0.8476\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0532 - accuracy: 0.9854 - val_loss: 0.4623 - val_accuracy: 0.8514\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0536 - accuracy: 0.9854 - val_loss: 0.4773 - val_accuracy: 0.8500\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 0.0519 - accuracy: 0.9861 - val_loss: 0.4710 - val_accuracy: 0.8444\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 6s 166ms/step - loss: 0.0500 - accuracy: 0.9863 - val_loss: 0.4755 - val_accuracy: 0.8434\n"
     ]
    }
   ],
   "source": [
    "MODEL = model.fit(padded_sequence,target,validation_split=0.2, epochs=15, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "349fa421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 406ms/step\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "test_word ='Pune is a not a good city'\n",
    "tw = tokenizer.texts_to_sequences([test_word])\n",
    "tw = pad_sequences(tw,maxlen=25)\n",
    "sentiment = int(model.predict(tw).round().item())\n",
    "#print(sentiment)\n",
    "if sentiment==0:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Positive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe57f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1696a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
